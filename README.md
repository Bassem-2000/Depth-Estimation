# Depth Estimation Comparison: Monocular vs Stereo Methods

This repository implements and compares monocular and stereo depth estimation methods on the CARLA simulator dataset, providing comprehensive quantitative and qualitative analysis.

## ğŸ¯ Project Overview

This project benchmarks different depth estimation approaches:
- **Monocular Depth Estimation**: MiDaS models (DPT_Large, DPT_Hybrid, MiDaS_Small)
- **Stereo Depth Estimation**: Semi-Global Block Matching (SGBM) variants

## ğŸ“ Repository Structure

```
depth-estimation-comparison/
â”œâ”€â”€ config.py                 # Model configurations and settings
â”œâ”€â”€ inference.py              # Main inference script
â”œâ”€â”€ visu.py                   # Quick visualization example
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ monocular/
â”‚   â”‚   â”‚   â””â”€â”€ midas.py      # MiDaS model implementations
â”‚   â”‚   â””â”€â”€ stereo/
â”‚   â”‚       â””â”€â”€ sgbm.py       # SGBM model implementations
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ data_loader.py    # CARLA dataset loader
â”‚       â”œâ”€â”€ evaluation.py     # Metrics calculation
â”‚       â””â”€â”€ visualization.py  # Visualization utilities
â”œâ”€â”€ results/                  # Generated results (created during inference)
â”œâ”€â”€ report.md                # Detailed analysis report
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md               # This file
```

## ğŸš€ Quick Start

### Prerequisites

```bash
pip install -r requirements.txt
```

### Basic Usage

1. **List available models:**
```bash
python inference.py --list_models
```

2. **Run inference on all models:**
```bash
python inference.py --data_path data/images --output_dir results
```

3. **Run specific model types:**
```bash
# Monocular models only
python inference.py --data_path data/images --mono --output_dir results

# Stereo models only
python inference.py --data_path data/images --stereo --output_dir results

# Specific models
python inference.py --data_path data/images --models midas_large sgbm_balanced
```

4. **Quick visualization test:**
```bash
python visu.py
```

## ğŸ“Š Available Models

### Monocular Models
- **midas_large**: MiDaS DPT Large - highest accuracy, slowest inference
- **midas_hybrid**: MiDaS DPT Hybrid - balanced accuracy and speed
- **midas_small**: MiDaS Small - fastest but less accurate

### Stereo Models
- **sgbm_fast**: SGBM Fast preset - faster but less accurate
- **sgbm_balanced**: SGBM Balanced preset - good speed/accuracy trade-off
- **sgbm_accurate**: SGBM Accurate preset - high accuracy but slower

## ğŸ“ˆ Evaluation Metrics

### Depth Metrics
- **abs_rel**: Absolute relative error
- **rmse**: Root mean square error
- **rmse_log**: Root mean square log error
- **a1, a2, a3**: Threshold accuracies (Î´ < 1.25, 1.25Â², 1.25Â³)

### Disparity Metrics
- **bad_1.0, bad_2.0, bad_3.0**: Bad pixel ratios (error > threshold)
- **mae**: Mean absolute error
- **rmse**: Root mean square error

## ğŸ—‚ï¸ Dataset Format

The CARLA dataset should be organized as:
```
data/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ left/          # Left stereo images
â”‚   â””â”€â”€ right/         # Right stereo images
â”œâ”€â”€ depth/             # Ground truth depth maps
â”œâ”€â”€ disparity/         # Ground truth disparity maps
â””â”€â”€ camera_config.json # Camera parameters (optional)
```

## ğŸ“‹ Command Line Arguments

- `--data_path`: Path to dataset directory (required)
- `--output_dir`: Output directory for results (default: results)
- `--num_samples`: Number of samples to evaluate (default: all)
- `--models`: Specific models to evaluate
- `--mono`: Evaluate all monocular models
- `--stereo`: Evaluate all stereo models
- `--device`: Device to use (cuda/cpu, default: auto-detect)
- `--list_models`: List available models and exit

## ğŸ“Š Output Files

After running inference, the following files are generated:

- `results/metrics.json`: Summary metrics for all models
- `results/detailed_metrics.json`: Per-sample detailed results
- `results/visualizations/`: Comparison visualizations for each sample
- `results/{model_name}/`: Individual depth maps for each model (if enabled)

## ğŸ”§ Configuration

Edit `config.py` to:
- Add new models
- Modify evaluation settings
- Change visualization parameters
- Adjust default model selections

## ğŸ“ Results Analysis

See `report.md` for detailed analysis including:
- Quantitative performance comparison
- Qualitative analysis with example cases
- Strengths and weaknesses of each approach
- Failure case analysis
- Recommendations for different use cases

## ğŸ› ï¸ Dependencies

- Python 3.7+
- PyTorch
- OpenCV
- NumPy
- Matplotlib
- tqdm

See `requirements.txt` for complete list with versions.

## ğŸ“š References

- **MiDaS**: [Towards Robust Monocular Depth Estimation](https://arxiv.org/abs/1907.01341)
- **SGBM**: Semi-Global Matching algorithm from OpenCV
- **CARLA**: [Open-source simulator for autonomous driving research](https://carla.org/)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™‹â€â™‚ï¸ Support

For questions or issues, please:
1. Check the documentation
2. Review existing issues
3. Create a new issue with detailed description

---

**Note**: This implementation is designed for academic research and comparison purposes. For production use, consider additional optimizations and error handling.
